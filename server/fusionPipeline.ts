// AUTO-GENERATED BY KIRO
// REVIEW REQUIRED: Face detection and masking policy
// REVIEW REQUIRED: HuggingFace API key management
import { v2 as cloudinary } from "cloudinary";
import { storage } from "./storage.js";
import type { FusionJob } from "../shared/schema.js";

// HuggingFace API configuration
const HF_API_URL = "https://api-inference.huggingface.co/models";
const HF_API_KEY = process.env.HUGGINGFACE_API_KEY;
const USE_MOCK = !HF_API_KEY || process.env.NODE_ENV === "development";

// Models
const SEGMENTATION_MODEL = "briaai/RMBG-2.0"; // Background removal
const INPAINTING_MODEL = "runwayml/stable-diffusion-inpainting";
const IMAGE_TO_IMAGE_MODEL = "stabilityai/stable-diffusion-2-inpainting";

interface ImageFeatures {
  palette: string[]; // Hex colors
  dominantPattern: string;
  garmentType: string;
}

/**
 * Detect faces in image using Cloudinary
 * REVIEW REQUIRED: Policy decision on auto-mask vs consent
 */
export async function detectFaces(imageUrl: string): Promise<{
  hasFaces: boolean;
  faceCount: number;
  faces?: Array<{ x: number; y: number; width: number; height: number }>;
}> {
  try {
    // Use Cloudinary's face detection
    const result = await cloudinary.api.resource(
      imageUrl.split("/").pop()?.split(".")[0] || "",
      {
        resource_type: "image",
        faces: true,
      }
    );

    const faces = result.faces || [];
    return {
      hasFaces: faces.length > 0,
      faceCount: faces.length,
      faces: faces.map((f: any) => ({
        x: f[0],
        y: f[1],
        width: f[2],
        height: f[3],
      })),
    };
  } catch (error) {
    console.error("Face detection error:", error);
    // If face detection fails, assume no faces (safer for demo)
    return { hasFaces: false, faceCount: 0 };
  }
}

/**
 * Extract features from image (palette, patterns, garment type)
 */
export async function extractFeatures(imageUrl: string): Promise<ImageFeatures> {
  // TODO: Implement actual feature extraction
  // For now, return mock data
  return {
    palette: ["#ff6b6b", "#9b59ff", "#ff8fb1", "#0b0f12"],
    dominantPattern: "paisley",
    garmentType: "saree",
  };
}

/**
 * Construct fusion prompt from templates
 */
function constructPrompt(
  imageAFeatures: ImageFeatures,
  imageBFeatures: ImageFeatures,
  mode: "pattern" | "color" | "texture"
): string {
  const templates = {
    pattern: `A ${imageAFeatures.garmentType} in ${imageAFeatures.palette[0]}, featuring the ${imageBFeatures.dominantPattern} pattern from Image B applied to the pallu region, maintaining the original silhouette and drape, Kiroween gothic fashion aesthetic, high quality, detailed, professional fashion photography, studio lighting, dark background with fog overlay`,
    color: `A ${imageAFeatures.garmentType} combining the color palette from Image A (${imageAFeatures.palette.join(", ")}) with accents from Image B (${imageBFeatures.palette.join(", ")}), creating a harmonious fusion, preserving the original silhouette, Kiroween gothic fashion, neon pink and purple accents, high quality, detailed`,
    texture: `A ${imageAFeatures.garmentType} with the ${imageBFeatures.dominantPattern} texture from Image B overlaid on the pallu of Image A, maintaining original structure, Kiroween aesthetic, spooky fog effects, Victorian gothic style, high quality, professional`,
  };

  return templates[mode];
}

/**
 * Call HuggingFace API for image-to-image generation
 * @param imageUrl - Base image (Image A)
 * @param prompt - Text prompt describing the fusion
 * @param negativePrompt - What to avoid in generation
 * @param strength - How much to transform (0.5-0.9)
 * @param imageBUrl - Second image to blend (Image B) - optional for mock mode
 */
async function callHuggingFace(
  imageUrl: string,
  prompt: string,
  negativePrompt: string,
  strength: number,
  imageBUrl?: string // Add imageB for blending
): Promise<string> {
  if (USE_MOCK) {
    // Return mock result for development - use Cloudinary to blend both images
    console.log("Using mock HuggingFace response - creating fused image from both inputs");
    console.log("Image A:", imageUrl);
    console.log("Image B:", imageBUrl);
    
    try {
      // For Cloudinary, we need to use the full URL or public ID
      // If images are already in Cloudinary, extract public ID
      // Otherwise, use fetch URL transformation
      
      let transformedUrl: string;

      if (imageBUrl) {
        // Use Cloudinary URL transformation with both images
        // Method 1: Use fetch URLs if images are external
        const isCloudinaryUrl = (url: string) => url.includes('cloudinary.com');
        
        if (isCloudinaryUrl(imageUrl) && isCloudinaryUrl(imageBUrl)) {
          // Both are Cloudinary URLs - extract public IDs
          const extractPublicId = (url: string) => {
            const match = url.match(/\/v\d+\/(.+)\.(jpg|png|jpeg|webp)/);
            return match ? match[1] : null;
          };
          
          const publicIdA = extractPublicId(imageUrl);
          const publicIdB = extractPublicId(imageBUrl);
          
          if (publicIdA && publicIdB) {
            transformedUrl = cloudinary.url(publicIdA, {
              transformation: [
                { width: 800, height: 1000, crop: "fill", quality: "auto:best" },
                { 
                  overlay: publicIdB,
                  width: 0.6,
                  height: 0.6,
                  gravity: "center",
                  opacity: Math.round(strength * 100),
                  effect: "multiply"
                },
                { effect: "art:audrey", quality: "auto:best" },
              ],
            });
          } else {
            // Fallback: use fetch URLs
            transformedUrl = cloudinary.url(imageUrl, {
              transformation: [
                { width: 800, height: 1000, crop: "fill", quality: "auto:best" },
                { 
                  overlay: imageBUrl,
                  width: 0.6,
                  height: 0.6,
                  gravity: "center",
                  opacity: Math.round(strength * 100),
                  effect: "multiply"
                },
                { effect: "art:audrey", quality: "auto:best" },
              ],
            });
          }
        } else {
          // Use fetch URLs for external images
          transformedUrl = cloudinary.url(imageUrl, {
            transformation: [
              { width: 800, height: 1000, crop: "fill", quality: "auto:best" },
              { 
                overlay: imageBUrl,
                width: 0.6,
                height: 0.6,
                gravity: "center",
                opacity: Math.round(strength * 100),
                effect: "multiply"
              },
              { effect: "art:audrey", quality: "auto:best" },
            ],
          });
        }
      } else {
        // Fallback: just transform imageA with effects
        transformedUrl = cloudinary.url(imageUrl, {
          transformation: [
            { width: 800, height: 1000, crop: "fill", quality: "auto:best" },
            { effect: "art:audrey", quality: "auto:best" },
            { effect: "vibrance:20" },
          ],
        });
      }
      
      console.log("Generated transformed URL:", transformedUrl);
      return transformedUrl;
    } catch (error) {
      console.error("Mock transformation error:", error);
      // Fallback: return imageA with timestamp to show it's different
      const separator = imageUrl.includes('?') ? '&' : '?';
      return `${imageUrl}${separator}t=${Date.now()}&fusion=mock&strength=${strength}`;
    }
  }

  try {
    const response = await fetch(`${HF_API_URL}/${IMAGE_TO_IMAGE_MODEL}`, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${HF_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        inputs: {
          image: imageUrl,
          prompt,
          negative_prompt: negativePrompt,
          strength,
          guidance_scale: 7.5,
          num_inference_steps: 25,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`HuggingFace API error: ${response.statusText}`);
    }

    const blob = await response.blob();
    // Upload result to Cloudinary
    const uploadResult = await uploadToCloudinary(blob);
    return uploadResult;
  } catch (error) {
    console.error("HuggingFace API error:", error);
    // Fallback to mock
    return imageUrl;
  }
}

/**
 * Upload blob to Cloudinary
 */
async function uploadToCloudinary(blob: Blob): Promise<string> {
  return new Promise(async (resolve, reject) => {
    try {
      const arrayBuffer = await blob.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      const uploadStream = cloudinary.uploader.upload_stream(
        {
          folder: "fusion/results",
          resource_type: "image",
          transformation: [{ quality: "auto:best" }],
        },
        (error, result) => {
          if (error) reject(error);
          else resolve(result!.secure_url);
        }
      );
      uploadStream.end(buffer);
    } catch (error) {
      reject(error);
    }
  });
}

/**
 * Generate explainability data (heatmap, designer note, contributions)
 */
export async function generateExplainability(
  imageA: string,
  imageB: string,
  resultUrl: string,
  mode: "pattern" | "color" | "texture"
): Promise<{
  heatmap: string; // Base64
  designerNote: string;
  contributionRegions: Array<{
    region: string;
    contribution: number;
    pattern: string;
  }>;
}> {
  // TODO: Implement actual explainability generation
  // For now, return mock data
  const regions = {
    pattern: [
      { region: "Pallu", contribution: 0.8, pattern: "Paisley" },
      { region: "Border", contribution: 0.6, pattern: "Floral" },
      { region: "Body", contribution: 0.3, pattern: "Geometric" },
    ],
    color: [
      { region: "Overall", contribution: 0.7, pattern: "Color Fusion" },
      { region: "Accents", contribution: 0.5, pattern: "Neon Highlights" },
    ],
    texture: [
      { region: "Pallu", contribution: 0.9, pattern: "Texture Overlay" },
      { region: "Border", contribution: 0.4, pattern: "Subtle Texture" },
    ],
  };

  const notes = {
    pattern: `Used motif from waist panel of Image B to decorate the pallu, maintaining the original drape and silhouette. The paisley pattern adds gothic elegance while preserving traditional structure.`,
    color: `Harmoniously blended color palettes from both images, creating a cohesive fusion that maintains the original garment's form while introducing vibrant gothic accents.`,
    texture: `Applied ${mode} texture from Image B to the pallu region, creating depth and visual interest while preserving the original garment's silhouette and drape.`,
  };

  return {
    heatmap: "", // TODO: Generate actual heatmap
    designerNote: notes[mode],
    contributionRegions: regions[mode],
  };
}

/**
 * Upscale image using Cloudinary
 */
export async function upscaleImage(imageUrl: string): Promise<string> {
  try {
    const publicId = imageUrl.split("/").pop()?.split(".")[0] || "";
    const upscaledUrl = cloudinary.url(publicId, {
      transformation: [
        { quality: "auto:best", dpr: 2.0, width: 2048, height: 2048, crop: "limit" },
      ],
    });
    return upscaledUrl;
  } catch (error) {
    console.error("Upscaling error:", error);
    return imageUrl; // Return original if upscaling fails
  }
}

/**
 * Main fusion pipeline
 */
export async function processFusionJob(jobId: string): Promise<void> {
  const job = await storage.getFusionJob(jobId);
  if (!job) {
    throw new Error(`Fusion job ${jobId} not found`);
  }

  try {
    // Update status to processing
    await storage.updateFusionJob(jobId, {
      status: "processing",
      progress: 10,
    });

    // Step 1: Detect faces (REVIEW REQUIRED)
    const facesA = await detectFaces(job.imageA);
    const facesB = await detectFaces(job.imageB);

    if ((facesA.hasFaces || facesB.hasFaces) && !process.env.AUTO_MASK_FACES) {
      // Abort if faces detected and auto-mask not enabled
      await storage.updateFusionJob(jobId, {
        status: "failed",
        error: "Faces detected. Please provide consent for face masking or use images without faces.",
        progress: 0,
      });
      return;
    }

    await storage.updateFusionJob(jobId, { progress: 20 });

    // Step 2: Extract features
    const featuresA = await extractFeatures(job.imageA);
    const featuresB = await extractFeatures(job.imageB);

    await storage.updateFusionJob(jobId, {
      progress: 30,
      metadata: {
        paletteA: featuresA.palette,
        paletteB: featuresB.palette,
        dominantPattern: featuresB.dominantPattern,
        garmentType: featuresA.garmentType,
      },
    });

    // Step 3: Construct prompt
    const prompt = constructPrompt(featuresA, featuresB, job.mode);
    const negativePrompt = "faces, distorted faces, low quality, blurry, distorted shapes, extra limbs, missing limbs, text, watermark, signature, bad anatomy, deformed, ugly, duplicate, mutilated";

    await storage.updateFusionJob(jobId, { progress: 40 });

    // Step 4: Generate fusion (3 candidates)
    const candidates: string[] = [];
    for (let i = 0; i < 3; i++) {
      const candidate = await callHuggingFace(
        job.imageA,
        prompt,
        negativePrompt,
        job.strength
      );
      candidates.push(candidate);
      await storage.updateFusionJob(jobId, {
        progress: 40 + (i + 1) * 15, // 40, 55, 70
        candidates: candidates.slice(),
      });
    }

    // Step 5: Select best candidate (use first for now)
    const resultUrl = candidates[0];

    await storage.updateFusionJob(jobId, {
      progress: 75,
      resultUrl,
    });

    // Step 6: Upscale
    const upscaledUrl = await upscaleImage(resultUrl);
    await storage.updateFusionJob(jobId, {
      progress: 85,
      resultUrl: upscaledUrl,
    });

    // Step 7: Generate explainability
    const explainability = await generateExplainability(
      job.imageA,
      job.imageB,
      upscaledUrl,
      job.mode
    );

    await storage.updateFusionJob(jobId, {
      progress: 95,
      explainability,
    });

    // Step 8: Complete
    await storage.updateFusionJob(jobId, {
      status: "completed",
      progress: 100,
    });
  } catch (error: any) {
    console.error("Fusion pipeline error:", error);
    await storage.updateFusionJob(jobId, {
      status: "failed",
      error: error.message || "Fusion processing failed",
      progress: 0,
    });
  }
}

