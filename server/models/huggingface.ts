// AUTO-GENERATED BY KIRO
// HuggingFace Inference API wrapper
// REVIEW REQUIRED: API key management and rate limiting

const HF_API_URL = "https://api-inference.huggingface.co/models";
const HF_API_KEY = process.env.HUGGINGFACE_API_KEY;

// Get fetch function (node-fetch or global fetch)
async function getFetch() {
  try {
    // Try to use node-fetch if available (optional dependency)
    // @ts-ignore - node-fetch is optional
    const nodeFetch = await import("node-fetch").catch(() => null);
    if (nodeFetch) {
      return nodeFetch.default as any;
    }
  } catch {
    // Ignore
  }
  // Use global fetch (available in Node 18+)
  return globalThis.fetch;
}

export interface HFModelResponse {
  output?: string | Blob | ArrayBuffer; // Image data
  error?: string;
}

/**
 * Call HuggingFace Inference API
 */
export async function callHFModel(
  modelId: string,
  inputs: Record<string, unknown>,
  options?: { returnBlob?: boolean }
): Promise<HFModelResponse> {
  if (!HF_API_KEY) {
    throw new Error("HUGGINGFACE_API_KEY not configured");
  }

  try {
    const fetchFn = await getFetch();
    const response = await fetchFn(`${HF_API_URL}/${modelId}`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${HF_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(inputs),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`HuggingFace API error: ${response.status} ${errorText}`);
    }

    if (options?.returnBlob) {
      const blob = await response.blob();
      return { output: blob };
    }

    const data = await response.json() as HFModelResponse;
    return data;
  } catch (error: any) {
    console.error("HuggingFace API error:", error);
    throw error;
  }
}

/**
 * Face detection using HuggingFace (damo/retinaface)
 */
export async function detectFacesHF(imageUrl: string): Promise<{
  hasFaces: boolean;
  faceCount: number;
  faces?: Array<{ x: number; y: number; width: number; height: number }>;
}> {
  try {
    const result = await callHFModel("damo/retinaface", {
      inputs: imageUrl,
    });

    // Parse response (adjust based on actual HF response format)
    const faces = (result.output as any)?.faces || [];
    return {
      hasFaces: faces.length > 0,
      faceCount: faces.length,
      faces: faces.map((f: any) => ({
        x: f.x || f[0],
        y: f.y || f[1],
        width: f.width || f[2],
        height: f.height || f[3],
      })),
    };
  } catch (error) {
    console.error("HF face detection error:", error);
    return { hasFaces: false, faceCount: 0 };
  }
}

/**
 * SAM segmentation using HuggingFace (facebook/sam-vit-base)
 */
export async function segmentImageHF(
  imageUrl: string,
  prompts?: Array<{ type: "point" | "box"; coordinates: number[] }>
): Promise<{
  masks: Array<{ mask: string; score: number }>; // Base64 masks
}> {
  try {
    const result = await callHFModel("facebook/sam-vit-base", {
      inputs: {
        image: imageUrl,
        prompts: prompts || [],
      },
    });

    return {
      masks: (result.output as any)?.masks || [],
    };
  } catch (error) {
    console.error("HF SAM segmentation error:", error);
    return { masks: [] };
  }
}

/**
 * ControlNet + Stable Diffusion image-to-image
 * Note: HuggingFace Inference API may not support ControlNet directly
 * This is a simplified version that uses image-to-image
 */
export async function generateImageHF(
  initImage: string,
  prompt: string,
  negativePrompt: string,
  controlnetImage: string, // Edge map or condition image (used if supported)
  options: {
    strength: number;
    guidanceScale?: number;
    steps?: number;
    controlnetWeight?: number;
  }
): Promise<Blob> {
  try {
    // Try ControlNet model first, fallback to regular SD image-to-image
    const modelId = "runwayml/stable-diffusion-v1-5"; // Standard SD for image-to-image
    
    const fetchFn = await getFetch();
    const response = await fetchFn(`${HF_API_URL}/${modelId}`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${HF_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        inputs: {
          image: initImage,
          prompt,
          negative_prompt: negativePrompt,
          strength: options.strength,
          guidance_scale: options.guidanceScale || 7.5,
          num_inference_steps: options.steps || 25,
        },
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`HuggingFace API error: ${response.status} ${errorText}`);
    }

    const blob = await response.blob();
    return blob;
  } catch (error) {
    console.error("HF image generation error:", error);
    throw error;
  }
}

/**
 * Real-ESRGAN upscaling (xinntao/Real-ESRGAN)
 */
export async function upscaleImageHF(imageUrl: string, scale: number = 2): Promise<Blob> {
  try {
    const result = await callHFModel(
      "xinntao/real-esrgan",
      {
        inputs: imageUrl,
        scale,
      },
      { returnBlob: true }
    );

    if (!result.output || !(result.output instanceof Blob)) {
      throw new Error("Invalid response from HuggingFace");
    }

    return result.output;
  } catch (error) {
    console.error("HF upscaling error:", error);
    throw error;
  }
}

/**
 * CLIP feature extraction (openai/clip-vit-base-patch32)
 */
export async function extractCLIPFeatures(imageUrl: string): Promise<number[]> {
  try {
    const result = await callHFModel("openai/clip-vit-base-patch32", {
      inputs: {
        image: imageUrl,
      },
    });

    return (result.output as any)?.embeddings || [];
  } catch (error) {
    console.error("HF CLIP extraction error:", error);
    return [];
  }
}

