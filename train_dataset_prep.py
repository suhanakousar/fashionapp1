# AUTO-GENERATED BY KIRO
# Dataset Preparation Script for Fashion Fusion Training
# Prepares training pairs: (mannequin_template, fabric_images) -> (target_image)

import json
import os
from pathlib import Path
from typing import List, Dict, Tuple
import shutil

# Configuration
INPUT_DIR = "./data/raw"
OUTPUT_DIR = "./data/training"
CATEGORIES = ["lehenga", "blouse", "gown", "saree", "salwar", "dress", "top", "skirt"]

def prepare_dataset(category: str) -> None:
    """
    Prepare training dataset for a garment category.
    
    Expected structure:
    data/raw/{category}/
      - images/  # Real images of mannequin wearing garments
      - mannequins/  # Canonical mannequin templates
      - fabrics/  # Fabric images
      - masks/  # Segmentation masks (top/bottom/pallu regions)
      - metadata.json  # Annotations
    """
    input_path = Path(INPUT_DIR) / category
    output_path = Path(OUTPUT_DIR) / category
    
    if not input_path.exists():
        print(f"Warning: Input directory not found: {input_path}")
        print("Creating example structure...")
        create_example_structure(input_path)
        return
    
    # Create output directory
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Load metadata
    metadata_file = input_path / "metadata.json"
    if metadata_file.exists():
        with open(metadata_file, "r") as f:
            metadata = json.load(f)
    else:
        print(f"Warning: metadata.json not found. Creating template...")
        create_metadata_template(input_path)
        metadata = []
    
    # Process each training sample
    training_pairs = []
    
    for idx, item in enumerate(metadata):
        # Expected format:
        # {
        #   "id": "sample_001",
        #   "target_image": "images/sample_001.jpg",
        #   "mannequin_template": "mannequins/template.jpg",
        #   "fabric_top": "fabrics/top_001.jpg",
        #   "fabric_bottom": "fabrics/bottom_001.jpg",
        #   "fabric_trims": "fabrics/trims_001.jpg",
        #   "mask_top": "masks/top_001.png",
        #   "mask_bottom": "masks/bottom_001.png",
        #   "prompt": "Photorealistic lehenga with paisley pattern...",
        #   "category": "lehenga"
        # }
        
        sample_id = item.get("id", f"sample_{idx:03d}")
        
        # Copy files to output directory
        sample_dir = output_path / sample_id
        sample_dir.mkdir(exist_ok=True)
        
        # Copy target image
        target_src = input_path / item["target_image"]
        if target_src.exists():
            shutil.copy(target_src, sample_dir / "target.jpg")
        else:
            print(f"Warning: Target image not found: {target_src}")
            continue
        
        # Copy mannequin template
        mannequin_src = input_path / item["mannequin_template"]
        if mannequin_src.exists():
            shutil.copy(mannequin_src, sample_dir / "mannequin.jpg")
        else:
            print(f"Warning: Mannequin template not found: {mannequin_src}")
            continue
        
        # Copy fabric images
        for fabric_type in ["fabric_top", "fabric_bottom", "fabric_trims"]:
            if fabric_type in item:
                fabric_src = input_path / item[fabric_type]
                if fabric_src.exists():
                    shutil.copy(fabric_src, sample_dir / f"{fabric_type}.jpg")
        
        # Copy masks
        for mask_type in ["mask_top", "mask_bottom"]:
            if mask_type in item:
                mask_src = input_path / item[mask_type]
                if mask_src.exists():
                    shutil.copy(mask_src, sample_dir / f"{mask_type}.png")
        
        # Save metadata
        with open(sample_dir / "metadata.json", "w") as f:
            json.dump(item, f, indent=2)
        
        training_pairs.append({
            "id": sample_id,
            "target": str(sample_dir / "target.jpg"),
            "mannequin": str(sample_dir / "mannequin.jpg"),
            "prompt": item.get("prompt", ""),
        })
    
    # Create dataset index
    index_file = output_path / "dataset_index.json"
    with open(index_file, "w") as f:
        json.dump({
            "category": category,
            "num_samples": len(training_pairs),
            "samples": training_pairs,
        }, f, indent=2)
    
    print(f"Prepared {len(training_pairs)} training samples for {category}")
    print(f"Output directory: {output_path}")

def create_example_structure(input_path: Path) -> None:
    """Create example directory structure and metadata template"""
    input_path.mkdir(parents=True, exist_ok=True)
    
    for subdir in ["images", "mannequins", "fabrics", "masks"]:
        (input_path / subdir).mkdir(exist_ok=True)
    
    create_metadata_template(input_path)

def create_metadata_template(input_path: Path) -> None:
    """Create example metadata.json template"""
    template = [
        {
            "id": "sample_001",
            "target_image": "images/sample_001.jpg",
            "mannequin_template": "mannequins/template.jpg",
            "fabric_top": "fabrics/top_001.jpg",
            "fabric_bottom": "fabrics/bottom_001.jpg",
            "fabric_trims": "fabrics/trims_001.jpg",
            "mask_top": "masks/top_001.png",
            "mask_bottom": "masks/bottom_001.png",
            "prompt": "Photorealistic lehenga with paisley pattern on blouse and floral pattern on skirt, high quality, detailed",
            "category": "lehenga",
        }
    ]
    
    metadata_file = input_path / "metadata.json"
    with open(metadata_file, "w") as f:
        json.dump(template, f, indent=2)
    
    print(f"Created metadata template at {metadata_file}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        categories = [sys.argv[1]]
    else:
        categories = CATEGORIES
    
    for category in categories:
        print(f"\nPreparing dataset for {category}...")
        prepare_dataset(category)

